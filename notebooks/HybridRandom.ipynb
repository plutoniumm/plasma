{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current problem we're facing is\n",
    "\n",
    "> The simulations run too slow. An average iteration in `Net` below for a classical layer takes ~10ns whereas for a quantum layer it takes ~0.5s, that too parallelized to (8/16 threads)\n",
    "\n",
    "This is most likely since most of Qiskit is written in Python and not in C-family/Fortran top to bottom. In fact the only C layer in all of Qiskit is the `Aer` package which is why it takes 0.5s and not something like 15s.\n",
    "\n",
    "There is no way I know of so far of circumventing this problem. the following are a few considerations:\n",
    "- Using **TorchQuantum**: TorchQuantum does not support Apple Silicon installations (i am using an M2 laptop). The issue is tracked [here](https://github.com/mit-han-lab/torchquantum/issues/98)\n",
    "- Use the **GPU**: The current Benchmark for M2 CPU is faster than the Colab GPU\n",
    "- Using **Apple Silicon** to its full extent: While pytorch is already ready for it, Qiskit is not. The issue is tracked [here](https://github.com/Qiskit/qiskit-aer/issues/1762). With full Apple Silicon support, we can use the M2 to basically as much power as the same order of magnitude as Titan\n",
    "- Using a **Different Algorithm**: See [QCNN.ipynb](./QCNN.ipynb)\n",
    "- Using **Runtime Primitives**: The `EstimatorQNN` class actually returns the energy levels measured in various ways. The circuit is not learning when using those/I don't know how to use it (since I can't find a lot of examples online)\n",
    "- Using `TorchConnector`: There is no speed/learning benefit. Under the hood it uses the same `EstimatorQNN` class\n",
    "\n",
    "### The situation\n",
    "We know for a fact this model works because under various configurations we are seeing learning happening. For $(0,1)$ case it is almost a perfect classifier. For $(0,1,3,6)$ case for small training size it is random but as the trainset becomes larger it starts becoming more and more better than random (I was able to reach ~40%, perfectly random is ~25%)\n",
    "\n",
    "It stands to reason if Qiskit were faster we would see the same thing happening for the full MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Function\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "from qiskit_aer.primitives import Estimator\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit import QuantumCircuit\n",
    "from time import time\n",
    "\n",
    "from utils import gtt\n",
    "\n",
    "n_train = 100\n",
    "n_test = 10\n",
    "qubits = 13\n",
    "shots = 1024\n",
    "\n",
    "# train_loader, test_loader = gtt(n_train, [i for i in range(10)])\n",
    "train_loader, test_loader = gtt(n_train, [0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NC4 from I, X, Y, Z\n",
    "paulis = [\"I\", \"X\", \"Y\", \"Z\"]\n",
    "def select(n):\n",
    "    if n == 0:\n",
    "        return [\"\"]\n",
    "    if n == 1:\n",
    "        return [\"I\", \"X\", \"Y\", \"Z\"]\n",
    "    return [a+b for a in select(n-1) for b in paulis]\n",
    "\n",
    "class QuantumCircuitGen:\n",
    "    def __init__(self, qubits):\n",
    "        print(\"Initializing QuantumCircuitGen with\", qubits, \"qubits\")\n",
    "        self.backend = Estimator()\n",
    "        possible = select(5 if qubits > 5 else qubits)\n",
    "        possible = np.random.choice(possible, qubits)\n",
    "        if qubits > 5:\n",
    "            possible = [\"I\"*(qubits-5)+p for p in possible]\n",
    "        self.obs = [self.op(p) for p in possible]\n",
    "\n",
    "        circ = QuantumCircuit(qubits)\n",
    "        for i in range(qubits):\n",
    "            circ.h(i)\n",
    "            t = Parameter('t'+str(i))\n",
    "            circ.cx(i, (i+1)%qubits)\n",
    "            circ.rx(t, i)\n",
    "        circ.measure_all()\n",
    "        self.circuit = circ\n",
    "\n",
    "    def op(self, p):\n",
    "        return SparsePauliOp.from_list([(p, 1)])\n",
    "\n",
    "    def run(self, inputs): # Runs a circuit\n",
    "        qc = self.circuit.assign_parameters(inputs)\n",
    "        result = self.backend.run(\n",
    "            [qc]*len(self.obs),\n",
    "            self.obs,\n",
    "            shots=shots,\n",
    "        ).result()\n",
    "        return torch.tensor(result.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridFunction(Function):\n",
    "    def forward(ctx, input, quantum_circuit):\n",
    "        ctx.shift = np.pi / 2;\n",
    "        ctx.quantum_circuit = quantum_circuit\n",
    "\n",
    "        results = [];\n",
    "        for i in range(len(input)):\n",
    "            expectation_z = ctx.quantum_circuit.run(input[i].tolist())\n",
    "            results.append(torch.tensor(np.array([expectation_z])))\n",
    "\n",
    "        # Save the input and the result for the backward pass\n",
    "        results = torch.stack(results).squeeze(1)\n",
    "        ctx.save_for_backward(input, results)\n",
    "\n",
    "        return results\n",
    "\n",
    "    def backward(ctx, grad_output):\n",
    "        input, expectation_z = ctx.saved_tensors  # Load the saved tensors\n",
    "        input_list = np.array(input.tolist())\n",
    "\n",
    "        shift_right = input_list + np.ones(input_list.shape) * ctx.shift\n",
    "        shift_left = input_list - np.ones(input_list.shape) * ctx.shift\n",
    "\n",
    "        gradients = []\n",
    "        for i in range(len(input_list)):\n",
    "            # THIS IS WHY IT DOESNT WORK\n",
    "            # small changes may lead to large differences in the output\n",
    "            # like 10000 -> 00000 is a difference of 16 not 1\n",
    "            expectation_right = ctx.quantum_circuit.run(shift_right[i])\n",
    "            expectation_left = ctx.quantum_circuit.run(shift_left[i])\n",
    "            print(\"R:\", expectation_right)\n",
    "            print(\"L:\", expectation_left)\n",
    "\n",
    "            gradient = torch.tensor(np.array([expectation_right])) - \\\n",
    "                torch.tensor(np.array([expectation_left]))\n",
    "            print(\"G:\", gradient)\n",
    "            gradients.append(gradient)\n",
    "\n",
    "        gradients = torch.stack(gradients).squeeze(1)\n",
    "        return gradients * grad_output.float(), None, None\n",
    "\n",
    "class Hybrid(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Hybrid, self).__init__()\n",
    "        self.quantum_circuit = QuantumCircuitGen(13)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return HybridFunction.apply(input, self.quantum_circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing QuantumCircuitGen with 13 qubits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mt/y75db3512zv_8r60rn4pb82h0000gn/T/ipykernel_68315/3309645063.py:13: DeprecationWarning: Option approximation=False is deprecated as of qiskit-aer 0.13. It will be removed no earlier than 3 months after the release date. Instead, use BackendEstmator from qiskit.primitives.\n",
      "  self.backend = Estimator()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (dropout): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=256, out_features=13, bias=True)\n",
      "  (hybrid): Hybrid()\n",
      "  (fc2): Linear(in_features=13, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module): # the actual neural net as mentioned in the tutorial\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=4)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=4)\n",
    "        out_conv1 = F.max_pool2d(self.conv1(torch.rand(1,1,28,28)), 2);\n",
    "        out_conv2 = F.max_pool2d(self.conv2(out_conv1), 2)\n",
    "        self.dropout = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(out_conv2.view(1,-1).shape[1], qubits)\n",
    "        self.hybrid = Hybrid()\n",
    "        out_hybrid = self.hybrid(torch.rand(qubits,qubits))\n",
    "        self.fc2 = nn.Linear(out_hybrid.shape[1], 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x) # We don't relu this to prevent learning, we pass as-is to QC\n",
    "        x = self.hybrid(x).type(torch.FloatTensor)\n",
    "        x = self.fc2(x)\n",
    "        return x;\n",
    "\n",
    "model = Net();\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R: tensor([-0.0137, -0.0098, -0.0078, -0.0391,  0.0000, -0.0332,  0.0000,  0.0059,\n",
      "         0.0156,  0.0547, -0.0098,  0.0410, -0.0469], dtype=torch.float64)\n",
      "L: tensor([ 0.0273,  0.0020,  0.0371, -0.0020,  0.0547,  0.0059, -0.0254, -0.0391,\n",
      "        -0.0195,  0.0059,  0.0215, -0.0410,  0.0215], dtype=torch.float64)\n",
      "G: tensor([[-0.0410, -0.0117, -0.0449, -0.0371, -0.0547, -0.0391,  0.0254,  0.0449,\n",
      "          0.0352,  0.0488, -0.0312,  0.0820, -0.0684]], dtype=torch.float64)\n",
      "R: tensor([-0.0488, -0.0098, -0.0469, -0.0137,  0.0000,  0.0508, -0.0801, -0.0059,\n",
      "        -0.0039,  0.0352, -0.0508,  0.0293, -0.0059], dtype=torch.float64)\n",
      "L: tensor([ 0.0059,  0.0430,  0.0625,  0.0098,  0.0039,  0.0469,  0.0000, -0.0195,\n",
      "         0.0156,  0.0195,  0.0098, -0.0215, -0.0410], dtype=torch.float64)\n",
      "G: tensor([[-0.0547, -0.0527, -0.1094, -0.0234, -0.0039,  0.0039, -0.0801,  0.0137,\n",
      "         -0.0195,  0.0156, -0.0605,  0.0508,  0.0352]], dtype=torch.float64)\n",
      "R: tensor([-0.0215, -0.0410,  0.0039,  0.0156, -0.0371,  0.0000, -0.0020,  0.0254,\n",
      "        -0.0430,  0.0215,  0.0742,  0.0410,  0.0176], dtype=torch.float64)\n",
      "L: tensor([-0.0059, -0.0156,  0.0273,  0.0527, -0.0195, -0.0273, -0.0098, -0.0312,\n",
      "        -0.0039,  0.0078,  0.0059,  0.0254,  0.0059], dtype=torch.float64)\n",
      "G: tensor([[-0.0156, -0.0254, -0.0234, -0.0371, -0.0176,  0.0273,  0.0078,  0.0566,\n",
      "         -0.0391,  0.0137,  0.0684,  0.0156,  0.0117]], dtype=torch.float64)\n",
      "R: tensor([-0.0195, -0.0078,  0.0020,  0.0723,  0.0000, -0.0234, -0.0117,  0.0000,\n",
      "        -0.0156, -0.0430,  0.0391,  0.0000, -0.0547], dtype=torch.float64)\n",
      "L: tensor([-0.0332,  0.0117, -0.0215, -0.0020,  0.0176,  0.0762,  0.0605, -0.0449,\n",
      "        -0.0020, -0.0039, -0.0254,  0.0098, -0.0156], dtype=torch.float64)\n",
      "G: tensor([[ 0.0137, -0.0195,  0.0234,  0.0742, -0.0176, -0.0996, -0.0723,  0.0449,\n",
      "         -0.0137, -0.0391,  0.0645, -0.0098, -0.0391]], dtype=torch.float64)\n",
      "R: tensor([ 0.0098, -0.0098,  0.0176,  0.0449, -0.0059, -0.0098,  0.0176,  0.0605,\n",
      "         0.0020,  0.0254,  0.0195,  0.0527,  0.0117], dtype=torch.float64)\n",
      "L: tensor([-0.0215, -0.0020, -0.0176, -0.0020,  0.0215,  0.0059,  0.0078,  0.0195,\n",
      "        -0.0195,  0.0000,  0.0000,  0.0137,  0.0449], dtype=torch.float64)\n",
      "G: tensor([[ 0.0312, -0.0078,  0.0352,  0.0469, -0.0273, -0.0156,  0.0098,  0.0410,\n",
      "          0.0215,  0.0254,  0.0195,  0.0391, -0.0332]], dtype=torch.float64)\n",
      "R: tensor([-0.0137,  0.0059,  0.0117,  0.0371,  0.0352, -0.0605, -0.0234, -0.0391,\n",
      "        -0.0234,  0.0273,  0.0234, -0.0273, -0.0020], dtype=torch.float64)\n",
      "L: tensor([-0.0078, -0.0312,  0.0195, -0.0645,  0.0000, -0.0039,  0.0352,  0.0273,\n",
      "         0.0293, -0.0156, -0.0215, -0.0527,  0.0098], dtype=torch.float64)\n",
      "G: tensor([[-0.0059,  0.0371, -0.0078,  0.1016,  0.0352, -0.0566, -0.0586, -0.0664,\n",
      "         -0.0527,  0.0430,  0.0449,  0.0254, -0.0117]], dtype=torch.float64)\n",
      "R: tensor([-0.0469, -0.0078,  0.0098,  0.0410, -0.0156, -0.0078, -0.0098, -0.0254,\n",
      "        -0.0488, -0.0293,  0.0234, -0.0195, -0.0215], dtype=torch.float64)\n",
      "L: tensor([-0.0312, -0.0137,  0.0859, -0.0176,  0.0020,  0.0254,  0.0312, -0.0176,\n",
      "        -0.0566,  0.0098, -0.0117, -0.0352,  0.0273], dtype=torch.float64)\n",
      "G: tensor([[-0.0156,  0.0059, -0.0762,  0.0586, -0.0176, -0.0332, -0.0410, -0.0078,\n",
      "          0.0078, -0.0391,  0.0352,  0.0156, -0.0488]], dtype=torch.float64)\n",
      "R: tensor([-0.0215, -0.0312, -0.0586,  0.0176,  0.0332,  0.0098,  0.0117,  0.0137,\n",
      "         0.0000,  0.0117, -0.0039, -0.0488, -0.0195], dtype=torch.float64)\n",
      "L: tensor([ 0.0020, -0.0273, -0.0254, -0.0195, -0.0059,  0.0156, -0.0430, -0.0312,\n",
      "        -0.0586, -0.0137,  0.0469, -0.0508, -0.0469], dtype=torch.float64)\n",
      "G: tensor([[-0.0234, -0.0039, -0.0332,  0.0371,  0.0391, -0.0059,  0.0547,  0.0449,\n",
      "          0.0586,  0.0254, -0.0508,  0.0020,  0.0273]], dtype=torch.float64)\n",
      "R: tensor([ 0.0098,  0.0137,  0.0449,  0.0410,  0.0059, -0.0293,  0.0547,  0.0176,\n",
      "         0.1035, -0.0293,  0.0176, -0.0176, -0.0449], dtype=torch.float64)\n",
      "L: tensor([ 0.0117,  0.0488,  0.0195,  0.0000,  0.0137,  0.0000,  0.0137, -0.0645,\n",
      "         0.0176, -0.0156, -0.0527, -0.0195,  0.0000], dtype=torch.float64)\n",
      "G: tensor([[-0.0020, -0.0352,  0.0254,  0.0410, -0.0078, -0.0293,  0.0410,  0.0820,\n",
      "          0.0859, -0.0137,  0.0703,  0.0020, -0.0449]], dtype=torch.float64)\n",
      "R: tensor([ 0.0293, -0.0137, -0.0410, -0.0410,  0.0508,  0.0566, -0.0254, -0.0137,\n",
      "         0.0371,  0.0176, -0.0195,  0.0039,  0.0273], dtype=torch.float64)\n",
      "L: tensor([-0.0234, -0.0215, -0.0176,  0.0234, -0.0234,  0.0195, -0.0098,  0.0293,\n",
      "        -0.0078,  0.0469, -0.0020,  0.0098,  0.0078], dtype=torch.float64)\n",
      "G: tensor([[ 0.0527,  0.0078, -0.0234, -0.0645,  0.0742,  0.0371, -0.0156, -0.0430,\n",
      "          0.0449, -0.0293, -0.0176, -0.0059,  0.0195]], dtype=torch.float64)\n",
      "R: tensor([-0.0664,  0.0137, -0.0312,  0.0234,  0.0430,  0.0195, -0.0410,  0.0332,\n",
      "        -0.0527,  0.0000, -0.0879, -0.0117, -0.0039], dtype=torch.float64)\n",
      "L: tensor([-0.0117,  0.0195,  0.0410,  0.0137, -0.0039,  0.0273, -0.0312, -0.0020,\n",
      "         0.0195,  0.0215, -0.0215, -0.0039, -0.0234], dtype=torch.float64)\n",
      "G: tensor([[-0.0547, -0.0059, -0.0723,  0.0098,  0.0469, -0.0078, -0.0098,  0.0352,\n",
      "         -0.0723, -0.0215, -0.0664, -0.0078,  0.0195]], dtype=torch.float64)\n",
      "R: tensor([ 0.0117,  0.0293,  0.0195,  0.0312, -0.0488, -0.0566, -0.0078, -0.0059,\n",
      "        -0.0156, -0.0098,  0.0059,  0.0000,  0.0098], dtype=torch.float64)\n",
      "L: tensor([ 0.0156, -0.0137, -0.0449, -0.0156,  0.0605, -0.0234,  0.0195, -0.0488,\n",
      "         0.0137, -0.0117,  0.0098, -0.0508, -0.0020], dtype=torch.float64)\n",
      "G: tensor([[-0.0039,  0.0430,  0.0645,  0.0469, -0.1094, -0.0332, -0.0273,  0.0430,\n",
      "         -0.0293,  0.0020, -0.0039,  0.0508,  0.0117]], dtype=torch.float64)\n",
      "R: tensor([ 0.0508, -0.0332, -0.0039, -0.0410,  0.0000,  0.0508,  0.0508,  0.0039,\n",
      "        -0.0078,  0.0586,  0.0039, -0.0488,  0.0352], dtype=torch.float64)\n",
      "L: tensor([ 0.0137, -0.0703, -0.0469,  0.0215,  0.0449,  0.0293,  0.0000,  0.0566,\n",
      "        -0.0508,  0.0215,  0.0098, -0.0410,  0.0039], dtype=torch.float64)\n",
      "G: tensor([[ 0.0371,  0.0371,  0.0430, -0.0625, -0.0449,  0.0215,  0.0508, -0.0527,\n",
      "          0.0430,  0.0371, -0.0059, -0.0078,  0.0312]], dtype=torch.float64)\n",
      "R: tensor([ 0.0117,  0.0332,  0.0234, -0.0059, -0.0234, -0.0391, -0.0410, -0.0156,\n",
      "        -0.0234,  0.0547, -0.0410, -0.0078,  0.0137], dtype=torch.float64)\n",
      "L: tensor([ 0.0000, -0.0352, -0.0547,  0.0117,  0.0059, -0.0098, -0.0273, -0.0059,\n",
      "         0.0137, -0.0078, -0.0391, -0.0215,  0.0078], dtype=torch.float64)\n",
      "G: tensor([[ 0.0117,  0.0684,  0.0781, -0.0176, -0.0293, -0.0293, -0.0137, -0.0098,\n",
      "         -0.0371,  0.0625, -0.0020,  0.0137,  0.0059]], dtype=torch.float64)\n",
      "R: tensor([-0.0117,  0.0156, -0.0488,  0.0566, -0.0039,  0.0234,  0.0332,  0.0059,\n",
      "        -0.0137,  0.0020,  0.0254,  0.0137, -0.0352], dtype=torch.float64)\n",
      "L: tensor([-0.0195, -0.0254, -0.0371,  0.0020, -0.0137, -0.0723, -0.0176,  0.0332,\n",
      "         0.0078, -0.0234,  0.0176, -0.0430, -0.0488], dtype=torch.float64)\n",
      "G: tensor([[ 0.0078,  0.0410, -0.0117,  0.0547,  0.0098,  0.0957,  0.0508, -0.0273,\n",
      "         -0.0215,  0.0254,  0.0078,  0.0566,  0.0137]], dtype=torch.float64)\n",
      "R: tensor([-0.0137,  0.0273,  0.0215,  0.0215, -0.0254, -0.0391,  0.0137, -0.0176,\n",
      "        -0.0039,  0.0293,  0.0234, -0.0078,  0.0332], dtype=torch.float64)\n",
      "L: tensor([-0.0293, -0.0547, -0.0469,  0.0586,  0.0410,  0.0234,  0.0039,  0.0039,\n",
      "         0.0137, -0.0430,  0.0039,  0.0371,  0.0371], dtype=torch.float64)\n",
      "G: tensor([[ 0.0156,  0.0820,  0.0684, -0.0371, -0.0664, -0.0625,  0.0098, -0.0215,\n",
      "         -0.0176,  0.0723,  0.0195, -0.0449, -0.0039]], dtype=torch.float64)\n",
      "R: tensor([-0.0020,  0.0078,  0.0078,  0.0117,  0.0098,  0.0000, -0.0117,  0.0234,\n",
      "        -0.0312,  0.0312, -0.0234,  0.0449,  0.0195], dtype=torch.float64)\n",
      "L: tensor([ 0.0332, -0.0039, -0.0742,  0.0078,  0.0000,  0.0352,  0.0391,  0.0059,\n",
      "        -0.0469, -0.0332, -0.0059,  0.0078,  0.0195], dtype=torch.float64)\n",
      "G: tensor([[-0.0352,  0.0117,  0.0820,  0.0039,  0.0098, -0.0352, -0.0508,  0.0176,\n",
      "          0.0156,  0.0645, -0.0176,  0.0371,  0.0000]], dtype=torch.float64)\n",
      "R: tensor([ 0.0176, -0.0469, -0.0371,  0.0078, -0.0254,  0.0059, -0.0039,  0.0039,\n",
      "         0.0195, -0.0195,  0.0156, -0.0586, -0.0156], dtype=torch.float64)\n",
      "L: tensor([ 0.0195,  0.0684,  0.0625,  0.0176, -0.0195, -0.0391,  0.0391, -0.0332,\n",
      "         0.0039, -0.0039, -0.0469,  0.0059,  0.0000], dtype=torch.float64)\n",
      "G: tensor([[-0.0020, -0.1152, -0.0996, -0.0098, -0.0059,  0.0449, -0.0430,  0.0371,\n",
      "          0.0156, -0.0156,  0.0625, -0.0645, -0.0156]], dtype=torch.float64)\n",
      "R: tensor([-0.0059, -0.0039,  0.0449,  0.0234,  0.0508,  0.0098, -0.0684, -0.0254,\n",
      "         0.0059,  0.0078,  0.0039, -0.0293,  0.0332], dtype=torch.float64)\n",
      "L: tensor([-0.0078,  0.0176, -0.0039, -0.0488,  0.0039, -0.0410,  0.0078,  0.0664,\n",
      "        -0.0020,  0.0527, -0.0098,  0.0430, -0.0215], dtype=torch.float64)\n",
      "G: tensor([[ 0.0020, -0.0215,  0.0488,  0.0723,  0.0469,  0.0508, -0.0762, -0.0918,\n",
      "          0.0078, -0.0449,  0.0137, -0.0723,  0.0547]], dtype=torch.float64)\n",
      "R: tensor([-0.0410, -0.0156, -0.0391, -0.0039,  0.0234, -0.0391, -0.0254,  0.0098,\n",
      "         0.0156,  0.0020, -0.0215,  0.0098,  0.0000], dtype=torch.float64)\n",
      "L: tensor([-0.0781,  0.0391,  0.0234, -0.0098, -0.0469, -0.0352, -0.0293, -0.0273,\n",
      "         0.0430, -0.0117, -0.0059,  0.0059, -0.0176], dtype=torch.float64)\n",
      "G: tensor([[ 0.0371, -0.0547, -0.0625,  0.0059,  0.0703, -0.0039,  0.0039,  0.0371,\n",
      "         -0.0273,  0.0137, -0.0156,  0.0039,  0.0176]], dtype=torch.float64)\n",
      "R: tensor([ 0.0332, -0.0039, -0.0312,  0.0059, -0.0137,  0.0000, -0.0117, -0.0039,\n",
      "        -0.0176, -0.0371, -0.0430,  0.0000, -0.0020], dtype=torch.float64)\n",
      "L: tensor([-0.0410,  0.0488, -0.0312,  0.0488,  0.0156,  0.0195, -0.0039, -0.0020,\n",
      "        -0.0410,  0.0742,  0.0332,  0.0312, -0.0273], dtype=torch.float64)\n",
      "G: tensor([[ 0.0742, -0.0527,  0.0000, -0.0430, -0.0293, -0.0195, -0.0078, -0.0020,\n",
      "          0.0234, -0.1113, -0.0762, -0.0312,  0.0254]], dtype=torch.float64)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 24\u001b[0m\n\u001b[1;32m     20\u001b[0m targets\u001b[38;5;241m.\u001b[39mappend(target)\n\u001b[1;32m     22\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_func(output, target) \u001b[38;5;66;03m# Loss\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     27\u001b[0m total_loss\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pyx64/lib/python3.11/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pyx64/lib/python3.11/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pyx64/lib/python3.11/site-packages/torch/autograd/function.py:289\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    284\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImplementing both \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackward\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvjp\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for a custom \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    285\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction is not allowed. You should only implement one \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof them.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    287\u001b[0m     )\n\u001b[1;32m    288\u001b[0m user_fn \u001b[38;5;241m=\u001b[39m vjp_fn \u001b[38;5;28;01mif\u001b[39;00m vjp_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Function\u001b[38;5;241m.\u001b[39mvjp \u001b[38;5;28;01melse\u001b[39;00m backward_fn\n\u001b[0;32m--> 289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43muser_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 35\u001b[0m, in \u001b[0;36mHybridFunction.backward\u001b[0;34m(ctx, grad_output)\u001b[0m\n\u001b[1;32m     30\u001b[0m gradients \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(input_list)):\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m# THIS IS WHY IT DOESNT WORK\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# small changes may lead to large differences in the output\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# like 10000 -> 00000 is a difference of 16 not 1\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m     expectation_right \u001b[38;5;241m=\u001b[39m \u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantum_circuit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshift_right\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m     expectation_left \u001b[38;5;241m=\u001b[39m ctx\u001b[38;5;241m.\u001b[39mquantum_circuit\u001b[38;5;241m.\u001b[39mrun(shift_left[i])\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mR:\u001b[39m\u001b[38;5;124m\"\u001b[39m, expectation_right)\n",
      "Cell \u001b[0;32mIn[9], line 38\u001b[0m, in \u001b[0;36mQuantumCircuitGen.run\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs): \u001b[38;5;66;03m# Runs a circuit\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     qc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcircuit\u001b[38;5;241m.\u001b[39massign_parameters(inputs)\n\u001b[1;32m     34\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mqc\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshots\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshots\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m---> 38\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(result\u001b[38;5;241m.\u001b[39mvalues)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pyx64/lib/python3.11/site-packages/qiskit/primitives/primitive_job.py:55\u001b[0m, in \u001b[0;36mPrimitiveJob.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the results of the job.\"\"\"\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_submitted()\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_future\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pyx64/lib/python3.11/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 451\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pyx64/lib/python3.11/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001) # Adam optimizer\n",
    "loss_func = nn.CrossEntropyLoss() # Cross entropy loss since we're doing classification\n",
    "\n",
    "epochs = 20 # for now 20\n",
    "loss_list = [3] # we need to intialize this to something, 3 is arbitrary\n",
    "\n",
    "model.train() # Set the model to training mode\n",
    "\n",
    "outputs = []\n",
    "targets = []\n",
    "for epoch in range(epochs):\n",
    "    total_loss = []\n",
    "    times = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        now = time()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "\n",
    "        outputs.append(torch.argmax(output))\n",
    "        targets.append(target)\n",
    "\n",
    "        loss = loss_func(output, target) # Loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss.append(loss.item())\n",
    "        times.append(time() - now)\n",
    "\n",
    "    print(f\"Avg Itr Time: {np.round(np.average(times),1)}s x {len(times)} itrs = {np.round(np.sum(times)/60,1)}min\")\n",
    "    loss_list.append(sum(total_loss)/len(total_loss))\n",
    "\n",
    "    diff = np.abs(loss_list[-1] - loss_list[-2]) /loss_list[-1];\n",
    "    if diff <= 0.001: # Early stopping criterial loss diff = 0.1%\n",
    "        break;\n",
    "\n",
    "    print(f'Training [{100. * (epoch + 1) / epochs:.0f}%]\\tLoss: {loss_list[-1]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval() # Set the model to evaluation mode\n",
    "with torch.no_grad(): # Don't compute gradients\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(test_loader): # Loop over the test set\n",
    "        output = model(data)\n",
    "\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        loss = loss_func(output, target)\n",
    "        total_loss.append(loss.item())\n",
    "\n",
    "    print('Performance on test data:\\n\\tLoss: {:.4f}\\n\\tAccuracy: {:.1f}%'.format(\n",
    "        sum(total_loss) / len(total_loss),\n",
    "        correct / len(test_loader) * 100)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "n_samples_show = 6\n",
    "count = 0\n",
    "fig, axes = plt.subplots(nrows=1, ncols=n_samples_show, figsize=(10, 3))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        if count == n_samples_show:\n",
    "            break\n",
    "        output = model(data)\n",
    "        print(output)\n",
    "\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "\n",
    "        axes[count].imshow(data[0].numpy().squeeze(), cmap='gray')\n",
    "\n",
    "        axes[count].set_xticks([])\n",
    "        axes[count].set_yticks([])\n",
    "        axes[count].set_title('Predicted {}'.format(pred.item()))\n",
    "\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For dark mode\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    "  html{filter:invert(1)}\n",
    "  div.prompt{opacity: 0.5;}\n",
    "  .btn-default{border-color: transparent;}\n",
    "  #header-container{display:none !important;}\n",
    "  div.cell.selected, div.cell.selected.jupyter-soft-selected{border-color: transparent;}\n",
    "</style>\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
